# Ollama Strands Agent

á»¨ng dá»¥ng full-stack sá»­ dá»¥ng **Strands Agent SDK** vá»›i **Ollama** (local LLM) Ä‘á»ƒ xÃ¢y dá»±ng AI agents cho chat vÃ  trÃ­ch xuáº¥t hÃ³a Ä‘Æ¡n.

## ğŸš€ CÃ´ng nghá»‡

- **Backend:** Strands Agent SDK, FastAPI, Pydantic, Ollama
- **Frontend:** React, Vite
- **Infrastructure:** Docker & Docker Compose

## ğŸ“‹ YÃªu cáº§u

- Docker Desktop
- Tá»‘i thiá»ƒu 4GB RAM

## ğŸ› ï¸ CÃ i Ä‘áº·t vÃ  cháº¡y

### BÆ°á»›c 1: Clone repository
```bash
git clone https://github.com/NguyenNgocTrieuVy1404/Ollama_Strands_Agent.git
cd ollama_strands_agent
```

### BÆ°á»›c 2: Pull Ollama model (QUAN TRá»ŒNG!)

**CÃ¡ch 1: Pull model trÆ°á»›c khi start (Khuyáº¿n nghá»‹)**
```bash
# Start Ollama container
docker-compose up ollama -d

# Äá»£i Ollama khá»Ÿi Ä‘á»™ng (10-20 giÃ¢y), sau Ä‘Ã³ pull model
docker exec -it ollama_strands ollama pull qwen2.5:3b
```

**CÃ¡ch 2: Pull model sau khi start**
```bash
docker-compose up --build -d
docker exec -it ollama_strands ollama pull qwen2.5:3b
docker-compose restart backend
```

**LÆ°u Ã½:** Model Ä‘Æ°á»£c lÆ°u trong Docker volume, chá»‰ cáº§n pull má»™t láº§n.

### BÆ°á»›c 3: Start services
```bash
docker-compose up --build
```

### BÆ°á»›c 4: Truy cáº­p á»©ng dá»¥ng
- **Frontend:** http://localhost:5173
- **Backend API:** http://localhost:8000
- **Ollama API:** http://localhost:11434

## âš™ï¸ Cáº¥u hÃ¬nh

### Thay Ä‘á»•i model Ollama

Sá»­a trong `docker-compose.yml`:
```yaml
environment:
  - OLLAMA_MODEL=qwen2.5:3b  # Thay Ä‘á»•i model á»Ÿ Ä‘Ã¢y
```

Sau Ä‘Ã³ pull model má»›i vÃ  restart:
```bash
docker exec -it ollama_strands ollama pull <model-name>
docker-compose restart backend
```

## ğŸ”§ TÃ­nh nÄƒng

- **Chat Agent:** TÆ°Æ¡ng tÃ¡c chat vá»›i AI (`POST /api/chat`)
- **Invoice Extraction:** TrÃ­ch xuáº¥t thÃ´ng tin hÃ³a Ä‘Æ¡n vá»›i Structured Output (`POST /api/extract-invoice`)

**LÆ°u Ã½:** Sá»­ dá»¥ng `agent.invoke_async(prompt, structured_output_model=Model)` - khÃ´ng dÃ¹ng deprecated `structured_output()` method.

## ğŸ“ LÆ°u Ã½ quan trá»ng

### Strands Agent SDK
- Import: `from strands.models.ollama import OllamaModel`
- Khá»Ÿi táº¡o: `OllamaModel(host=..., model_id=...)`
- DÃ¹ng `structured_output_model` parameter khi gá»i agent

### Model Ollama
- Model `qwen2.5:3b` phÃ¹ há»£p mÃ¡y yáº¿u nhÆ°ng cÃ³ thá»ƒ thiáº¿u má»™t sá»‘ trÆ°á»ng optional
- Náº¿u cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n, dÃ¹ng model lá»›n hÆ¡n (7b+)

## ğŸ› Troubleshooting

**Model not found:**
```bash
docker exec -it ollama_strands ollama pull qwen2.5:3b
```

**Cannot connect to Ollama:**
- Kiá»ƒm tra container: `docker ps`
- Kiá»ƒm tra `OLLAMA_BASE_URL` trong `docker-compose.yml`

**Structured output failed:**
- Model cÃ³ thá»ƒ quÃ¡ nhá», thá»­ model lá»›n hÆ¡n
- Xem logs: `docker-compose logs backend`

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Strands Agent SDK](https://strandsagents.com/latest/documentation/docs/)
- [Strands Structured Output](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/agents/structured-output/)
- [Ollama Documentation](https://ollama.ai/docs)
